{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web_Scraping.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM71/AhT9OFWGuRp5iI8LxJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Denis718/Web-Scraping-Python-BS4/blob/main/Web_Scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95DIKxRQQXzl"
      },
      "source": [
        "## Web Scraping com Python e Beautiful Soup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Steaaui6Qu57"
      },
      "source": [
        "<h2>Conteúdo</h2>\n",
        "\n",
        "*   Inspecionar a estrutura HTML do site de destino com as ferramentas de desenvolvedor do navegador\n",
        "*   Decifrar dados codificados em URLs\n",
        "*   Usar *request* e *Beautiful Soup* para extrair e analisar dados da Web\n",
        "*    Percorrer um pipeline de web scraping do início ao fim\n",
        "*   Criar um script que busque ofertas de emprego na Web e exiba informações relevantes no console"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GGIkI-BP_fR"
      },
      "source": [
        "import requests\n",
        "\n",
        "URL = \"https://realpython.github.io/fake-jobs/\"\n",
        "page = requests.get(URL)\n",
        "\n",
        "print(page.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUO4lk0mS4Ue",
        "outputId": "11f5c2ce-f984-4017-a525-2c983fc0f494"
      },
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCGSKwTkS8e1"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "URL = \"https://realpython.github.io/fake-jobs/\"\n",
        "page = requests.get(URL)\n",
        "\n",
        "soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "\n",
        "print(page.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hK5biABTAX2"
      },
      "source": [
        "results = soup.find(id=\"ResultsContainer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWlo7MgoTAjL"
      },
      "source": [
        "print(results.prettify()) # .prettify() - método utilizado para formatar o conteúdo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj8k_IxCTAvS"
      },
      "source": [
        "# identificando a tag do conteúdo desejado\n",
        "job_elements = results.find_all(\"div\", class_=\"card-content\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDWRLERrTA3X"
      },
      "source": [
        "for job_element in job_elements:\n",
        "  print(job_element, end=\"\\n\"*2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVoKFZZLTA72"
      },
      "source": [
        "# separando os elementos para apresentar o resultado\n",
        "for job_element in job_elements:\n",
        "  title_element = job_element.find(\"h2\", class_=\"title\")\n",
        "  company_element = job_element.find(\"h3\", class_=\"company\")\n",
        "  location_element = job_element.find(\"p\", class_=\"location\")\n",
        "  print(title_element)\n",
        "  print(company_element)\n",
        "  print(location_element)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcxzrblUTBE0"
      },
      "source": [
        "# exibindo somente o texto de cada elemento\n",
        "for job_element in job_elements:\n",
        "  title_element = job_element.find(\"h2\", class_=\"title\")\n",
        "  company_element = job_element.find(\"h3\", class_=\"company\")\n",
        "  location_element = job_element.find(\"p\", class_=\"location\")\n",
        "  print(title_element.text) # .text - Exibe somente o texto de cada elemento HTML\n",
        "  print(company_element.text)\n",
        "  print(location_element.text)\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LLvN1WkTBHS"
      },
      "source": [
        "# eliminando o excesso de espaços do texto\n",
        "for job_element in job_elements:\n",
        "  title_element = job_element.find(\"h2\", class_=\"title\")\n",
        "  company_element = job_element.find(\"h3\", class_=\"company\")\n",
        "  location_element = job_element.find(\"p\", class_=\"location\")\n",
        "  print(title_element.text.strip()) # .strip() - Remove os espaços em branco supérfluos\n",
        "  print(company_element.text.strip())\n",
        "  print(location_element.text.strip())\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_eYiO2rTBJS"
      },
      "source": [
        "# Filtrar pela vaga de emprego de interesse- Desenvolvedor Python\n",
        "python_jobs = results.find_all(\"h2\", string=\"Python\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nMNGCepTBPq"
      },
      "source": [
        "print(python_jobs) # não encontra pela string, devido a procura de texto exato"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dvudPapTBR7"
      },
      "source": [
        "# utilização de lambda para extrair o texto com qualquer formatação\n",
        "python_jobs = results.find_all(\"h2\", string = lambda text: \"python\" in text.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZkHNPFiUQzO",
        "outputId": "edfe48ad-dc9f-48bd-cd46-0d8791524262"
      },
      "source": [
        "print(len(python_jobs)) # total de jobs encontrados"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uV4eQRiUVqc",
        "outputId": "603db9df-43c9-4878-b429-59c21f070154"
      },
      "source": [
        "print(python_jobs[0].text) # selecionando apenas um elementos da lista"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Senior Python Developer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO0tQCzBUc4V"
      },
      "source": [
        "python_jobs = results.find_all(\n",
        "    \"h2\", string = lambda text: \"python\" in text.lower()\n",
        "    )\n",
        "\n",
        "# acessando elemento pai para extrair demais informações das vagas desejadas\n",
        "python_job_elements = [\n",
        "    h2_element.parent.parent.parent for h2_element in python_jobs\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ0jYjYPVBrz"
      },
      "source": [
        "# tentando capturar os links das vagas, porém selecionado o texto\n",
        "for job_element in python_job_elements:\n",
        "  #print(job_element.text)\n",
        "  links = job_element.find_all(\"a\")\n",
        "  for link in links:\n",
        "    print(link.text.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk1koDVYVPvE"
      },
      "source": [
        "# capturando somente o link de aplicação da vaga\n",
        "for job_element in python_job_elements:\n",
        "  #print(job_element.text)\n",
        "  links = job_element.find_all(\"a\")\n",
        "  #for link in links:\n",
        "  link_url = links[1][\"href\"]\n",
        "  print(f\"Apply here: {link_url}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEw4vXLCVXi1"
      },
      "source": [
        "# escrevendo um arquivo CSV com os resultados gerados\n",
        "import csv\n",
        "\n",
        "header = ['Job-Title', 'Company', 'Location', 'Link']\n",
        "dados = []\n",
        "\n",
        "for job_element in python_job_elements:\n",
        "  title_element = job_element.find(\"h2\", class_=\"title\")\n",
        "  company_element = job_element.find(\"h3\", class_=\"company\")\n",
        "  location_element = job_element.find(\"p\", class_=\"location\")\n",
        "  link = job_element.find_all(\"a\")[1][\"href\"]\n",
        "  dados.append([title_element.text.strip(), \n",
        "                company_element.text.strip(), \n",
        "                location_element.text.strip(), \n",
        "                link]\n",
        "               )\n",
        "  \n",
        "with open(\"Vagas_Python.csv\", \"w\", newline=\"\") as vagas_py_csv:\n",
        "  writer = csv.writer(vagas_py_csv, delimiter = \";\")\n",
        "  writer.writerow(header)\n",
        "  writer.writerows(dados)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kq9UQgZoRFv",
        "outputId": "ad12921e-bde7-4372-dcab-54d669dd2de7"
      },
      "source": [
        "#lendo o arquivo .csv gerado\n",
        "\n",
        "with open('/content/Vagas_Python.csv', 'r') as jobs_py:\n",
        "  job_reader = csv.reader(jobs_py, delimiter = \";\")\n",
        "  for row in job_reader:\n",
        "    print(row)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Job-Title', 'Company', 'Location', 'Link']\n",
            "['Senior Python Developer', 'Payne, Roberts and Davis', 'Stewartbury, AA', 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html']\n",
            "['Software Engineer (Python)', 'Garcia PLC', 'Ericberg, AE', 'https://realpython.github.io/fake-jobs/jobs/software-engineer-python-10.html']\n",
            "['Python Programmer (Entry-Level)', 'Moss, Duncan and Allen', 'Port Sara, AE', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-20.html']\n",
            "['Python Programmer (Entry-Level)', 'Cooper and Sons', 'West Victor, AE', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-30.html']\n",
            "['Software Developer (Python)', 'Adams-Brewer', 'Brockburgh, AE', 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-40.html']\n",
            "['Python Developer', 'Rivera and Sons', 'East Michaelfort, AA', 'https://realpython.github.io/fake-jobs/jobs/python-developer-50.html']\n",
            "['Back-End Web Developer (Python, Django)', 'Stewart-Alexander', 'South Kimberly, AA', 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-60.html']\n",
            "['Back-End Web Developer (Python, Django)', 'Jackson, Ali and Mckee', 'New Elizabethside, AA', 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-70.html']\n",
            "['Python Programmer (Entry-Level)', 'Mathews Inc', 'Robertborough, AP', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-80.html']\n",
            "['Software Developer (Python)', 'Moreno-Rodriguez', 'Martinezburgh, AE', 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-90.html']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQLJq9tGpM5R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}